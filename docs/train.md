# Что такое обучение

<a><b>Обучение</b></a> - это процесс определения идеальных параметров (весов(weights) и отклонений(biases)), составляющих модель. Во время обучения система считывает примеры и постепенно корректирует параметры. В обучении каждый пример используется от нескольких раз до миллиардов раз.

Одно обновление параметров модели(весов и смещений) в процессе обучения = <code><b>1 итерации</b></code>

Размер батча(batch) определяет количество данных, обрабатываемых моделью за одну <b>итерацию</b>. Например, если размер батча(batch) равен <code>20</code>, то перед корректировкой параметров модель итерирует 20 примеров.

<a><b>Эпоха(Epoch)</b></a> - это полный проход по обучающему множеству, когда каждый признак обрабатывается один раз.

$$
epoch = \frac{датасет}{размер батча}
$$

??? note "Пример"
    Предположим следующее:

      * Датасет = 1 000 примеров.
      * Размер батча = 50 примеров.
      * Одна эпоха = (1 000 / 50) => 20 итераций:

## Обобщение (generalization)

[Обобщение](https://serokell.io/blog/k-means-clustering-in-machine-learning) - это способности вашей модели должным образом адаптироваться к новым, ранее неизвестным данным


![Alt text](<images/High bias.webp>)

## Переобучение модели / overfitting

Переобучение (overfitting) - это явление, при котором модель машинного обучения слишком сильно адаптируется к обучающим данным, в результате чего она плохо работает на новых данных.

??? info "Пример"
    Рассмотрим задачу классификации рыб и птиц. У нас есть набор данных, в котором представлены примеры рыб и птиц с различными признаками, например, весом, окрасом, местом обитания и т.д.

    Модель машинного обучения может научиться различать рыб и птиц на этих данных, выявив закономерности между признаками и классами. Например, она может научиться определять, что все рыбы умеют плавать.

    На обучающих данных эта модель будет работать идеально. Она будет правильно определять, что рыба умеет плавать, а птица - нет.

    Однако, когда мы встретим утку, которая не встречалась ранее и она умеет плавать, то модель ошибочно определит утку как рыбу.

    Это произойдет потому, что модель слишком сильно учла закономерность, что все кто плавают рыбы 

    Представьте, что вы назначаете уникальный идентификатор каждому примеру и сопоставляете каждый идентификатор с его собственной функцией. Если вы не укажете функцию регуляризации, модель станет полностью подходящей. Это связано с тем, что модель будет пытаться свести потери к нулю во всех примерах и никогда не добьется этого, приводя веса для каждой функции индикатора к +бесконечности или -бесконечности. Это может произойти в многомерных данных с пересечениями признаков, когда существует огромная масса редких пересечений, каждое из которых происходит только в одном примере.

Наиболее распространенными способами борьбы с переобучение:

* L1-регуляризация штрафует модель за абсолютное значение весов признаков.
* L2-регуляризация штрафует модель за квадрат весов признаков.

Без регуляризации модель будет пытаться минимизировать функцию потерь, увеличивая веса признаков, которые она считает важными. Это может привести к переобучению, когда модель слишком хорошо подгоняется под обучающую выборку, но при этом плохо работает на новых данных.

### L1-регуляризация

\(L_1\)регуляризация, является методом регуляризации в машинном обучении, который добавляет штраф к функции потерь модели, пропорциональный сумме абсолютных значений весовых коэффициентов. Это приводит к тому, что некоторые веса становятся нулевыми, позволяя модели автоматически выбирать наиболее важные признаки и игнорировать менее значимые. Таким образом, L1 регуляризация обеспечивает отбор признаков и упрощение модели, что может помочь в предотвращении переобучения.

Штраф, который представлен суммой абсолютных значений весовых коэффициентов:

$$
L1 = \lambda \sum_{i=1}^{n} |w_i|
$$

Здесь:

- \( \lambda \) - это параметр регуляризации, который регулирует силу штрафа;
- \( n \) - количество признаков в модели;
- \( w_i \) - весовой коэффициент признака.

Добавление этого штрафа к функции потерь помогает модели выбирать наиболее важные признаки путем уменьшения весов нерелевантных признаков до нуля.

### L2-регуляризация

L2 регуляризация, представляет собой метод регуляризации в машинном обучении, при котором к функции потерь модели добавляется штраф, пропорциональный сумме квадратов весовых коэффициентов.

Формула для L2 регуляризации выглядит так:

$$
L2 = \lambda \sum_{i=1}^{n} w_i^2
$$

Здесь:

- \( \lambda \) - это параметр регуляризации, который контролирует силу штрафа;
- \( n \) - количество признаков в модели;
- \( w_i \) - весовой коэффициент признака.

В отличие от L1 регуляризации, L2 не стремится обнулить веса признаков, а скорее уменьшает их значения, делая их ближе к нулю без полного исключения из модели. Регуляризация L2 также помогает предотвратить переобучение, улучшая обобщающую способность линейных моделей.

??? info "Пример"
    Рассмотрим пример задачи классификации. Пусть мы хотим построить модель, которая предсказывает, будет ли человек покупать товар или нет.
    У нас есть обучающая выборка, состоящая из 

    m примеров. Каждый пример содержит информацию о товаре, а также о том, купил ли человек этот товар.
    Пусть у нас есть 

    n признаков, которые описывают товар. Например, это могут быть такие признаки, как цена товара, отзывы о товаре, наличие скидки и т.д.
    Без регуляризации модель может решить, что вес признака "цена товара" должен быть очень большим. Это означает, что модель будет предсказывать, что люди будут покупать товар только в том случае, если он будет очень дешевым.
    Регуляризация будет штрафовать модель за это. В результате модель уменьшит вес признака "цена товара". В результате модель будет предсказывать, что люди будут покупать товар и по более высокой цене.
    Таким образом, регуляризация помогает моделям машинного обучения избегать переобучения, заставляя их учитывать все возможные факторы, а не только один или два.

## Недообучения модель / underfitting

Недообучение модели в машинном обучении - это когда модель не может определить значимую связь между входными и выходными данными. 

## Три составляющие обучения

<a><b>Цель машинного обучения</b></a> — предсказать результат по входным данным. Чем разнообразнее входные данные, тем проще машине найти закономерности и тем точнее результат.

`Датасеты / Данные`

:   !!! warning "Важно"
        Большое количество данных и качество данных(Хотим определять спам — нужны примеры спам-писем, предсказывать курс акций — нужна история цен, узнать интересы пользователя — нужны его лайки или посты.)
    
    Семпл — это просто один экземпляр данных, который используется для обучения или тестирования модели машинного обучения. Он представляет собой набор значений признаков и целевой переменной. Например, в задаче распознавания изображений признаки могут включать размер изображения, цвет шерсти кота и другие характеристики.

    Так как прогонять весь датасет через модель ресурсоемкий процесс, то датасет делят на <b>батчи(batch)</b> или <b>мини-батчи(mini-batch)</b>

    Традиционно примеры в наборе данных делятся на следующие три различных подмножества:

    * <b>Обучающее множество(training set)</b> - подмножество набора данных, используемое для обучения модели.
    * <b>Валидационный набор(validation set)</b> - подмножество набора данных, на котором оцениваются результаты обучающего набора. Как правило, обученная модель оценивается на валидационном наборе несколько раз, прежде чем модель будет оценена на тестовом наборе.
    * <b>Tестовый набор(test set)</b> - подмножество набора данных, на котором перепроверяется оценка модели на данных которая она не видела после того, как модель «прошла» набор проверки. 

    ![Image](https://developers.google.com/static/machine-learning/crash-course/images/PartitionThreeSets.svg?hl=ru)

    ??? note "Кросс-валидация (Cross-validation)"
        Кросс-валидация заключается в разделении имеющегося набора данных на две или более части. Одна часть используется для обучения модели, а другая – для проверки ее качества. Этот процесс повторяется несколько раз с использованием разных разбиений данных, чтобы получить более надежную оценку производительности модели.

        Данные: A B C D E

        | Обучение| Валидация|
        | --------| ---------|
        | A B C D | E        |
        | A B C E | D        |
        | A B D E | C        |
        | A C D E | B        |
        | B C D E | A        |

        <h3>Hold-out</h3>

        Метод hold-out представляет из себя простое разделение на train и test:

        ![Alt text](<Total dataset.png>)

        Чтобы оценить модель, вы обучаете её на тренировочном множестве, а результаты измеряете на тестовом. Важно перед разделением на тренировочное и тестовое множества перемешать семплы. 

        ??? note "Почему важно перемешивать?"
            Когда данные не перемешиваются перед обучением модели, это влияет на то, как информация используется в процессе обучения. Например, если данные были упорядочены (например, сначала кошки, потом собаки), модель может выучить закономерности исходя из этого порядка, что может привести к проблемам в предсказаниях. Это особенно критично для моделей, использующих градиентный спуск, так как они могут застрять в определённых шаблонах данных и переобучиться, не учитывая всю информацию из датасета.

            ЕСЛИ ДАННЫХ МНОГО, ТО МОЖНО ИСПОЛЬЗОВАТЬ ВАЛИДАЦИОННОЕ  МНОЖЕСТВО

            При выборе моделей для вашей задачи оптимизируйте их на валидационном наборе данных, а финальное сравнение моделей проводите на тестовом наборе. 

            Оптимизация включает подбор гиперпараметров, архитектуры (для нейросетей), и определение оптимального порога для максимизации целевой метрики. 

            Если оптимизировать модели и сравнивать их на одном наборе данных, можно нечаянно включить информацию о тестовом наборе и получить менее точные результаты на новых данных.

        Для окончательного применения найденную лучшую модель можно обучить на всех имеющихся данных. Правда, вы не сможете оценить качество получившейся модели, так как у вас уже не будет тестового множества. Чтобы примерно оценить, как будет вести себя модель при добавлении новых данных, вы можете построить кривые обучения: графики качества модели на трейне и на тесте в зависимости от числа поданных семплов на вход. Кривые обучения могут выглядеть следующим образом

        ![Alt text](<Training score.png>)

        Модель слева показала итоговые результаты явно хуже модели справа (и график качества на валидации у неё близок к плато, хотя и продолжает расти), а качество модели справа могло бы ещё вырасти при добавлении дополнительных семплов (качество на трейне константно высокое, а на валидации возрастает).

        <h3>Стратификация (stratification)</h3>
        **Стратификация** - это способ разделить данные на тренировочную и тестовую выборки, сохраняя соотношение классов в исходном наборе данных.

        **Случайное разделение** может привести к тому, что распределение классов в тренировочной и тестовой выборках будет отличаться от распределения классов в исходном наборе данных. Например, в наборе данных Iris три класса цветов: Setosa, Versicolor и Virginica. Если мы случайно разделим этот набор данных на тренировочную и тестовую выборки, то вполне может оказаться, что в тренировочной выборке окажется больше цветов одного класса, чем в тестовой. Это может привести к тому, что модель машинного обучения, обученная на тренировочной выборке, будет плохо работать на тестовой.

        **Стратификация** помогает избежать этой проблемы. Она заключается в том, что при разделении данных на тренировочную и тестовую выборки сначала разбивают исходный набор данных на группы, называемые **стратами**. Затем выбираются тренировочная и тестовая выборки таким образом, чтобы в каждой из них было пропорциональное количество объектов из каждой страты.

        **Например**, если в наборе данных Iris три страты, соответствующие каждому классу цветов, то при стратификации тренировочная выборка будет содержать 33% объектов каждого класса, а тестовая выборка - 17% объектов каждого класса.

        **Стратификация** особенно полезна при работе с большими наборами данных, в которых один класс встречается намного чаще других. В таких случаях случайное разделение может привести к тому, что модель машинного обучения будет плохо обучаться на редких классах. Стратификация помогает избежать этой проблемы, обеспечивая, чтобы в тренировочной выборке было достаточно объектов из каждого класса.

        <h3>k-Fold?</h3>

        k-Fold — это один из методов кросс-валидации. Он заключается в следующем:

        1. Датасет разбивается на k равных частей (фолдов).
        2. На каждой итерации обучения модель обучается на k-1 фолдах, а тестируется на оставшемся фолде.
        3. В итоге получается k тестовых результатов, которые затем усредняются.

        **Как выбрать модель после k-Fold?**

        После применения k-Fold для одной модели у вас на руках останется несколько экземпляров этой модели, обученных на разных подмножествах трейна. Вы можете выбрать один из следующих вариантов:

        * Сделать предсказание с помощью усреднения предсказаний этих экземпляров.
        * Выбрать экземпляр с лучшим скором на тестовом фолде.
        * Заново обучить модель уже на всех фолдах и делать предсказания уже этой моделью.


        В методе k-fold **k** - это количество фолдов, на которые разбивается датасет. **k** фолдов означает, что на каждой итерации обучения модель обучается на **k-1** фолдах, а тестируется на оставшемся фолде.

        Например, если **k=5**, то датасет будет разбит на 5 фолдов по 20% данных в каждом. На первой итерации обучения модель будет обучаться на 80% данных, а тестироваться на оставшихся 20%. На второй итерации модель будет обучаться на 20% данных, которые не были использованы на первой итерации, а тестироваться на оставшихся 80%. И так далее.

        Чем больше **k**, тем более точно будет оцениваться качество модели. Однако, при увеличении **k** также увеличивается количество итераций обучения и тестирования, что может привести к увеличению вычислительных затрат.

        В реальных задачах обычно выбирают **k=5** или **k=10**.

        <h3>LOO-метод</h3>
        **LOO-метод** - это способ проверить, насколько хорошо модель предсказывает данные, которые она не видела раньше. Он работает так: из набора данных отбирают один образец, обучают модель на оставшихся образцах, а затем проверяют, насколько точно модель предсказывает значение этого отложенного образца.

        **LOO-метод может быть полезен, если у вас очень мало данных.** В этом случае вы хотите использовать все данные для обучения модели, а LOO-метод позволяет вам это сделать, откладывая только один образец на каждой итерации.

        **Однако LOO-метод неприменим для средних и больших задач.** Это связано с тем, что количество итераций будет равно количеству образцов в наборе данных. Если набор данных большой, то это может занять много времени и ресурсов.

        ??? note "Пример"
            Представим, что у нас есть набор данных из 10 образцов. Мы хотим использовать LOO-метод, чтобы проверить, насколько хорошо модель предсказывает значение цвета волос.

            На первой итерации мы откладываем первый образец. Затем мы обучаем модель на оставшихся 9 образцах. После этого мы используем модель, чтобы предсказать значение цвета волос первого образца.

            На второй итерации мы откладываем второй образец и повторяем процесс.

            Мы продолжаем этот процесс, пока не отложим все 10 образцов.

            В конце мы получим 10 значений, которые показывают, насколько точно модель предсказывает значение цвета волос каждого отложенного образца.

        <h3>Stratified k-Fold</h3>
        Метод stratified k-Fold — это метод k-Fold, использующий стратификацию при разбиении на фолды: каждый фолд содержит примерно такое же соотношение классов, как и всё исходное множество. Такой подход может потребоваться в случае, например, очень несбалансированного соотношения классов, когда при обычном random split некоторые фолды могут либо вообще не содержать семплов каких-то классов, либо содержать их слишком мало.


`Признаки / Фичи`

:   <b>Признак</b> - это входная переменная, то есть переменная x в простой линейной регрессии. В простом проекте машинного обучения может
    использоваться один признак, в более сложном проекте машинного обучения - миллионы признаков, указанных как: x1, x2, … xn
    
    Для работы с объектом модель должна опираться на какие-то его свойства, например, доход человека, цвет левого верхнего пикселя на изображении
    или частоту встречаемости слова «интеграл» в тексте. Эти свойства обычно называются признаками, а совокупность свойств, которые мы выделили у объекта – его признаковым описанием.

    <b>Метка</b> — это то, что мы предсказываем — переменная y в простой линейной регрессии. Метка может быть будущей ценой на пшеницу, видом животного, изображенного на картинке, значением аудиоклипа или чем угодно.

    Разновидности фич:

    * <b>Численные</b> – например, рост или доход. Иногда отдельно выделяют вещественные и целочисленные признаки.
    * <b>Категориальные</b> - признаки принимают значения из некоторого дискретного множества. Например, профессия человека или день недели.

    [<b>feature engineering</b>](https://serokell.io/blog/k-means-clustering-in-machine-learning) - процесс дополнительных усилий для выявления признаков у объекта

`Алгоритм машинного обучения (learning algorithm)`

:   Алгоритм обучения — это процедура, которая превращает обучающую выборку в обученную модель.